{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22d568e2-2d2c-440c-9d15-f1ba6496cb4a",
   "metadata": {},
   "source": [
    "# 04 - RoBERTa Prompt Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eda4402-c310-4b26-92b0-1e5e4cb30dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully\n",
      "Prompt Tuning model class defined\n",
      "Device: cuda\n",
      "GPU: Tesla V100-SXM2-32GB\n",
      "Total VRAM: 31.73 GB\n",
      "Train samples: 1132\n",
      "Validation samples: 125\n",
      "Data Collator defined\n",
      "Tokenizer loaded: roberta-base\n",
      "Raw datasets for evaluation loaded\n",
      "Metric loaded\n",
      "compute_metrics function defined\n",
      "\n",
      "================================================================================\n",
      "Experiment: RoBERTa + Prompt Tuning\n",
      "================================================================================\n",
      "\n",
      "Creating Prompt Tuning model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Tuning model created\n",
      "  Virtual tokens: 64\n",
      "  Initialization: from vocab\n",
      "\n",
      "Prompt Tuning model ready\n",
      "  Virtual tokens: 64\n",
      "  Total params: 124,696,322\n",
      "  Trainable params: 50,690\n",
      "  Trainable ratio: 0.0407%\n",
      "\n",
      "================================================================================\n",
      "Dataset diagnostics\n",
      "================================================================================\n",
      "  Train[0] keys: dict_keys(['input_ids', 'attention_mask', 'start_positions', 'end_positions'])\n",
      "  input_ids length: 384\n",
      "  attention_mask length: 384\n",
      "  start_position: 46\n",
      "  end_position: 49\n",
      "  Val[0] keys: dict_keys(['input_ids', 'attention_mask', 'offset_mapping', 'example_id', 'start_positions', 'end_positions'])\n",
      "  example_id: isaacus--legalqaeval/microsoft--ms-marco/validation/00000/22765/986409/8\n",
      "  offset_mapping length: 384\n",
      "Temp output dir: /var/tmp/pbs.2168.cbis-pbs/roberta_prompt_o0f4xxsa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/pbs.2168.cbis-pbs/ipykernel_1567538/922220299.py:753: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start training...\n",
      "Train samples: 1132\n",
      "Validation samples: 125\n",
      "Learning rate: 0.03\n",
      "Epochs: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='710' max='710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [710/710 00:41, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.500800</td>\n",
       "      <td>2.596862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.620500</td>\n",
       "      <td>2.279152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.624900</td>\n",
       "      <td>2.232222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.336800</td>\n",
       "      <td>2.188013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.139600</td>\n",
       "      <td>2.142422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training finished\n",
      "  Training time: 0.69 minutes\n",
      "  Peak GPU memory: 1.63 GB\n",
      "\n",
      "Evaluating on validation set (fixed threshold 2.50)...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation results:\n",
      "  EM: 69.42\n",
      "  F1: 70.78\n",
      "\n",
      "Validation evaluation (detailed)...\n",
      "\n",
      "Evaluated samples: 121\n",
      "Ground truth — with answers: 60, without answers: 61\n",
      "Predictions — with answers: 24, without answers: 97\n",
      "\n",
      "— Predicted with answers (examples) —\n",
      "\n",
      "[Sample 3]\n",
      "Question: what does restriction on drivers license mean\n",
      "Context: Restricted Driver License. A restriction or condition is placed on a person's driver license when it is necessary to ensure the person is driving within his/her ability. Restrictions and conditions va...\n",
      "Predicted answer: \"A restriction or condition is placed on a person's driver license when it is necessary to ensure the person is driving within his/her ability.\"\n",
      "Ground truth: [\"A restriction or condition is placed on a person's driver license when it is necessary to ensure the person is driving within his/her ability.\"]\n",
      "Best span score: 1.9424\n",
      "CLS score: 3.2593\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 5]\n",
      "Question: Who issued the Royal Proclamation of 1736?\n",
      "Context: Following the treaty, King George III issued the Royal Proclamation of 1763 on October 7, 1763, which outlined the division and administration of the newly conquered territory, and to some extent cont...\n",
      "Predicted answer: \"King George III\"\n",
      "Ground truth: No answer\n",
      "Best span score: 3.7773\n",
      "CLS score: 3.6895\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 18]\n",
      "Question: how does the constitution provide justice\n",
      "Context: The Constitution of the United States of America is the supreme law of the United States. Empowered with the sovereign authority of the people by the framers and the consent of the legislatures of the...\n",
      "Predicted answer: \"The Constitution of the United States of America is the supreme law of the United States.\"\n",
      "Ground truth: ['The Constitution of the United States of America is the supreme law of the United States. Empowered with the sovereign authority of the people by the framers and the consent of the legislatures of the states, it is the source of all government powers, and also provides important limitations on the government that protect the fundamental rights of United States citizens.']\n",
      "Best span score: 1.6689\n",
      "CLS score: 3.7520\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 23]\n",
      "Question: How many of the six total packages available to broadcasters did Setanta give away?\n",
      "Context: Following a lengthy legal battle with the European Commission, which deemed the exclusivity of the rights to be against the interests of competition and the consumer, BSkyB's monopoly came to an end f...\n",
      "Predicted answer: \"In May 2006\"\n",
      "Ground truth: No answer\n",
      "Best span score: 1.6450\n",
      "CLS score: 3.8818\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 27]\n",
      "Question: when was the dtv transition\n",
      "Context: The Congressional deadline to transition to digital broadcasts was pushed back several times. Congress passed the Telecommunications Act of 1996 with the original transition date of December 31, 2006....\n",
      "Predicted answer: \"December 31, 2006\"\n",
      "Ground truth: ['First to December 31, 2008, then to February 17, 2009, and then finally to June 12, 2009.']\n",
      "Best span score: 1.5334\n",
      "CLS score: 3.3730\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 28]\n",
      "Question: the eighteenth amendment was the only amendment that dealt with a substantive social issue\n",
      "Context: t the Supreme Court acknowledged the provisions of Section 2 in some later decisions. In Minor v. Happersett (1875), the Supreme Court cited Section 2 as supporting its conclusion that the right to vo...\n",
      "Predicted answer: \"Section 2 as supporting its conclusion that the right to vote was not among the \"privileges and immunities of citizenship\" protected by Section 1.\"\n",
      "Ground truth: No answer\n",
      "Best span score: 2.2510\n",
      "CLS score: 3.6973\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 39]\n",
      "Question: What was the objective of Royal Proclamation of 1736?\n",
      "Context: Following the treaty, King George III issued the Royal Proclamation of 1763 on October 7, 1763, which outlined the division and administration of the newly conquered territory, and to some extent cont...\n",
      "Predicted answer: \"King George III\"\n",
      "Ground truth: No answer\n",
      "Best span score: 3.1699\n",
      "CLS score: 4.1729\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 43]\n",
      "Question: Parliament elects a second minister from whom?\n",
      "Context: The party, or parties, that hold the majority of seats in the Parliament forms the Scottish Government. In contrast to many other parliamentary systems, Parliament elects a First Minister from a numbe...\n",
      "Predicted answer: \"a First Minister\"\n",
      "Ground truth: No answer\n",
      "Best span score: 1.3579\n",
      "CLS score: 3.4932\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 45]\n",
      "Question: Who makes formal appointment or dismissal decisions?\n",
      "Context: The party, or parties, that hold the majority of seats in the Parliament forms the Scottish Government. In contrast to many other parliamentary systems, Parliament elects a First Minister from a numbe...\n",
      "Predicted answer: \"the Sovereign\"\n",
      "Ground truth: ['the Sovereign']\n",
      "Best span score: 2.2661\n",
      "CLS score: 4.0479\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 46]\n",
      "Question: is gerber a publicly traded company\n",
      "Context: The SOX Act is a legislation that was created in 2002, primarily for publicly traded companies in the United States, and it requires that companies have a firmer hold on their companies' governance an...\n",
      "Predicted answer: \"The SOX Act is a legislation that was created in 2002\"\n",
      "Ground truth: No answer\n",
      "Best span score: 0.6113\n",
      "CLS score: 3.0938\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 57]\n",
      "Question: who present the central budget in lok sabha\n",
      "Context: The Union Budget of India, also referred to as the Annual Financial Statement in the Article 112 of the Constitution of India, is the annual budget of the Republic of India. The Government presents it...\n",
      "Predicted answer: \"February so that it could be materialized before the commencement of new financial year in April\"\n",
      "Ground truth: No answer\n",
      "Best span score: 1.2222\n",
      "CLS score: 3.3662\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 59]\n",
      "Question: legend definition for drugs\n",
      "Context: Legend drug ; Legend drug What is a legend drug? A legend drug is a drug approved by the U.S. Food and Drug Administration that can be dispensed to the public only with a prescription from a medical d...\n",
      "Predicted answer: \"A legend drug is a drug approved by the U.\"\n",
      "Ground truth: ['A legend drug is a drug approved by the U.S. Food and Drug Administration that can be dispensed to the public only with a prescription from a medical doctor or other licensed practitioner.']\n",
      "Best span score: 2.9805\n",
      "CLS score: 3.0776\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 60]\n",
      "Question: what is reentry court\n",
      "Context: What is a reentry court? In California, a reentry court is a type of collaborative justice court for individuals who have been released from prison, have violated their terms of community supervision,...\n",
      "Predicted answer: \"a reentry court? In California\"\n",
      "Ground truth: ['In California, a reentry court is a type of collaborative justice court for individuals who have been released from prison, have violated their terms of community supervision, and have a history of substance abuse or mental health issues.']\n",
      "Best span score: 1.3291\n",
      "CLS score: 3.3936\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 65]\n",
      "Question: appropriations define\n",
      "Context: Definition of 'appropriation'. appropriation. An appropriation is an amount of money that a government or organization reserves for a particular purpose. The government raised defence appropriations b...\n",
      "Predicted answer: \"An appropriation is an amount of money that a government or organization reserves for a particular purpose. The government raised defence appropriations by 12 per cent\"\n",
      "Ground truth: No answer\n",
      "Best span score: 1.8125\n",
      "CLS score: 3.1978\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 70]\n",
      "Question: Issues dealt with at Westminster are not ones who is able to deal with?\n",
      "Context: Reserved matters are subjects that are outside the legislative competence of the Scotland Parliament. The Scottish Parliament is unable to legislate on such issues that are reserved to, and dealt with...\n",
      "Predicted answer: \"The Scottish Parliament is unable to legislate on such issues that are reserved to, and dealt with at, Westminster\"\n",
      "Ground truth: ['The Scottish Parliament']\n",
      "Best span score: 3.1968\n",
      "CLS score: 4.1816\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 79]\n",
      "Question: How many citizens conflict in a constitutional impasse?\n",
      "Context: Civil disobedience is usually defined as pertaining to a citizen's relation to the state and its laws, as distinguished from a constitutional impasse in which two public agencies, especially two equal...\n",
      "Predicted answer: \"Civil disobedience\"\n",
      "Ground truth: No answer\n",
      "Best span score: 2.6614\n",
      "CLS score: 3.6738\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 82]\n",
      "Question: what is ncts\n",
      "Context: What is the NCT? The NCT is a compulsory vehicle inspection programme in Ireland. The primary aim of this programme which falls under the directive 2009/40/EC, is to improve road safety and enhance en...\n",
      "Predicted answer: \"The NCT is a compulsory vehicle inspection programme in Ireland.\"\n",
      "Ground truth: ['The NCT is a compulsory vehicle inspection programme in Ireland.']\n",
      "Best span score: 0.5781\n",
      "CLS score: 2.9897\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 84]\n",
      "Question: When was the Royal University of Prussia established?\n",
      "Context: Warsaw remained the capital of the Polish–Lithuanian Commonwealth until 1796, when it was annexed by the Kingdom of Prussia to become the capital of the province of South Prussia. Liberated by Napoleo...\n",
      "Predicted answer: \"The Royal University of Warsaw was established in 1816\"\n",
      "Ground truth: No answer\n",
      "Best span score: 2.5137\n",
      "CLS score: 3.6250\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 89]\n",
      "Question: What must the adoption of laws which will not have legal effect in the EU have?\n",
      "Context: The concept of legal certainty is recognised one of the general principles of European Union law by the European Court of Justice since the 1960s. It is an important general principle of international...\n",
      "Predicted answer: \"The adoption of laws which will have legal effect in the European Union must have a proper legal basis\"\n",
      "Ground truth: No answer\n",
      "Best span score: 3.0020\n",
      "CLS score: 4.3369\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 91]\n",
      "Question: what is copyright license\n",
      "Context: A copyright license agreement is a bargained-for agreement between a copyright holder and a party seeking to use copyrighted material. Such agreements often strictly limit the use of the material in q...\n",
      "Predicted answer: \"A copyright license agreement is a bargained-for agreement between a copyright holder and a party seeking to use copyrighted material.\"\n",
      "Ground truth: ['A copyright license agreement is a bargained-for agreement between a copyright holder and a party seeking to use copyrighted material.']\n",
      "Best span score: 2.9121\n",
      "CLS score: 2.7061\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 97]\n",
      "Question: what is contractual capacity mean\n",
      "Context: Capacity To Contract The legal ability to enter into a binding contract. Those who lack the capacity to contract include minors (with limited exceptions) and individuals who are so mentally impaired t...\n",
      "Predicted answer: \"The legal ability to enter into a binding contract.\"\n",
      "Ground truth: No answer\n",
      "Best span score: 1.5752\n",
      "CLS score: 3.0557\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 106]\n",
      "Question: How many member states adopted the Social Charter in 1989?\n",
      "Context: The Social Charter was subsequently adopted in 1989 by 11 of the then 12 member states. The UK refused to sign the Social Charter and was exempt from the legislation covering Social Charter issues unl...\n",
      "Predicted answer: \"11\"\n",
      "Ground truth: ['11 of the then 12 member states']\n",
      "Best span score: 2.5059\n",
      "CLS score: 3.9316\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 115]\n",
      "Question: When was the Social Charter not adopted?\n",
      "Context: The Social Charter was subsequently adopted in 1989 by 11 of the then 12 member states. The UK refused to sign the Social Charter and was exempt from the legislation covering Social Charter issues unl...\n",
      "Predicted answer: \"The Social Charter was subsequently adopted in 1989\"\n",
      "Ground truth: No answer\n",
      "Best span score: 2.6060\n",
      "CLS score: 3.9668\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 119]\n",
      "Question: how old must a person be to be elected governor?\n",
      "Context: In 35 states, the minimum age requirement of the governor is 30, though in some it is 25 (7), 21 (1), or 18 (5). Oklahoma is the only state with an older age, 31. Some states require the governor to b...\n",
      "Predicted answer: \"31\"\n",
      "Ground truth: No answer\n",
      "Best span score: 4.8193\n",
      "CLS score: 3.5918\n",
      "Decision: With answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "— Predicted no answer (examples) —\n",
      "\n",
      "[Sample 1]\n",
      "Question: who was president when nafta was passed\n",
      "Context: The North American Free Trade Agreement (NAFTA) is signed into law by President Bill Clinton. Clinton said he hoped the agreement would encourage other nations to work toward a broader world-trade pac...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: ['The North American Free Trade Agreement (NAFTA) is signed into law by President Bill Clinton.']\n",
      "Best span score: -1.9604\n",
      "CLS score: 3.5127\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 2]\n",
      "Question: What was the result in Montpellier of the Edict of Ales in 1629?\n",
      "Context: Montpellier was among the most important of the 66 \"villes de sûreté\" that the Edict of 1598 granted to the Huguenots. The city's political institutions and the university were all handed over to the ...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: No answer\n",
      "Best span score: -0.2490\n",
      "CLS score: 4.4248\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 4]\n",
      "Question: What party forms the Scottish Parliament?\n",
      "Context: The party, or parties, that hold the majority of seats in the Parliament forms the Scottish Government. In contrast to many other parliamentary systems, Parliament elects a First Minister from a numbe...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: ['The party, or parties, that hold the majority of seats in the Parliament']\n",
      "Best span score: 0.5215\n",
      "CLS score: 3.7393\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 6]\n",
      "Question: What is the primary goal of pleading not guilty when arrested for Civil Disobedience?\n",
      "Context: Steven Barkan writes that if defendants plead not guilty, \"they must decide whether their primary goal will be to win an acquittal and avoid imprisonment or a fine, or to use the proceedings as a foru...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: ['to win an acquittal and avoid imprisonment or a fine', 'to use the proceedings as a forum']\n",
      "Best span score: -1.6504\n",
      "CLS score: 3.6582\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 7]\n",
      "Question: What do the leaders of the opposition parties and other MSPs question the First Minister about?\n",
      "Context: Several procedures enable the Scottish Parliament to scrutinise the Government. The First Minister or members of the cabinet can deliver statements to Parliament upon which MSPs are invited to questio...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: ['issues related to the substance of the statement']\n",
      "Best span score: -2.0771\n",
      "CLS score: 3.9160\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 8]\n",
      "Question: When was the European Convention of Human Rights written?\n",
      "Context: None of the original treaties establishing the European Union mention protection for fundamental rights. It was not envisaged for European Union measures, that is legislative and administrative action...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: No answer\n",
      "Best span score: 1.0762\n",
      "CLS score: 4.0068\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 9]\n",
      "Question: When did Singer dispute the graph at a Senate hearing?\n",
      "Context: These studies were widely presented as demonstrating that the current warming period is exceptional in comparison to temperatures between 1000 and 1900, and the MBH99 based graph featured in publicity...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: ['May 2000', '18 July 2000']\n",
      "Best span score: -0.0386\n",
      "CLS score: 3.9121\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 10]\n",
      "Question: What can sympathetic Jurors in cases with civil disobedients?\n",
      "Context: Steven Barkan writes that if defendants plead not guilty, \"they must decide whether their primary goal will be to win an acquittal and avoid imprisonment or a fine, or to use the proceedings as a foru...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: ['jury nullification', 'jury nullification']\n",
      "Best span score: -2.1157\n",
      "CLS score: 3.4951\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 11]\n",
      "Question: who picks the chief justice of the illinois supreme court\n",
      "Context: the state supreme court, the highest court of the state of Illinois. The court's authority is granted in Article VI of the current Illinois Constitution, which provides for seven justices elected from...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: ['elected by the court from its members']\n",
      "Best span score: 1.0249\n",
      "CLS score: 3.7236\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 12]\n",
      "Question: example of how to write a contract for service\n",
      "Context: Tips. 1  You may want to have an attorney review and make suggestions on a template of your business contract. 2  An attorney can pinpoint issues for your particular business that you may need to incl...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: No answer\n",
      "Best span score: -1.2688\n",
      "CLS score: 3.0659\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 13]\n",
      "Question: Whose army liberated Warsaw in 1806?\n",
      "Context: Warsaw remained the capital of the Polish–Lithuanian Commonwealth until 1796, when it was annexed by the Kingdom of Prussia to become the capital of the province of South Prussia. Liberated by Napoleo...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: [\"Napoleon's\"]\n",
      "Best span score: 0.2363\n",
      "CLS score: 3.7002\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 14]\n",
      "Question: when was the second reconstruction act\n",
      "Context: In order to fully grasp the significance of the Reconstruction Acts of 1867, it is first necessary to understand the historical context in which they were created. These laws were passed and enforced ...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: No answer\n",
      "Best span score: -2.0098\n",
      "CLS score: 3.3516\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 15]\n",
      "Question: how much is a pennsylvania permit\n",
      "Context: A Pennsylvania license cannot be issued to a resident of another state who does not possess a current license or permit or similar document to carry a firearm issued by their home state if a license i...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: No answer\n",
      "Best span score: -2.0156\n",
      "CLS score: 2.8203\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 16]\n",
      "Question: extreme cruelty definition\n",
      "Context: Extreme Cruelty Law and Legal Definition. Extreme cruelty has been defined as acts and conduct which destroy the peace of mind and happiness of one of the parties to the marriage. The conduct must be ...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: ['Extreme cruelty has been defined as acts and conduct which destroy the peace of mind and happiness of one of the parties to the marriage.']\n",
      "Best span score: -0.6504\n",
      "CLS score: 2.6431\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 17]\n",
      "Question: what does preclearance mean customs\n",
      "Context: Sample Sentences & Example Usage. 1  Terri Sewell: The updated coverage formula in this bill will ensure that states, like Alabama, are required to obtain federal preclearance for changes to voting pr...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: No answer\n",
      "Best span score: -1.8770\n",
      "CLS score: 2.9521\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 19]\n",
      "Question: What enables the Scottish Parliament to scrutinize the government?\n",
      "Context: Several procedures enable the Scottish Parliament to scrutinise the Government. The First Minister or members of the cabinet can deliver statements to Parliament upon which MSPs are invited to questio...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: ['Several procedures']\n",
      "Best span score: 1.4561\n",
      "CLS score: 4.0664\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 20]\n",
      "Question: what county is connersville, in\n",
      "Context: The Indiana Supreme Court approves local court rules in only these areas: selection of special judges in civil and criminal cases, court reporter services, caseload allocation plans, and service as an...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: No answer\n",
      "Best span score: -5.0127\n",
      "CLS score: 3.0400\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 21]\n",
      "Question: What needs to be found to find out if rocks are related?\n",
      "Context: The principle of cross-cutting relationships pertains to the formation of faults and the age of the sequences through which they cut. Faults are younger than the rocks they cut; accordingly, if a faul...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: No answer\n",
      "Best span score: -3.2080\n",
      "CLS score: 3.1143\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 22]\n",
      "Question: Who were exempt from the Ministry of Justice?\n",
      "Context: While the existence of these central government departments and the Six Ministries (which had been introduced since the Sui and Tang dynasties) gave a Sinicized image in the Yuan administration, the a...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: ['Mongols and Semuren']\n",
      "Best span score: -4.6631\n",
      "CLS score: 3.2305\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 24]\n",
      "Question: why does ariel owe a debt to prospero\n",
      "Context: In act one scene 2 lines 318-360 we find out that Prospero freed Ariel form a pine tree. She was tied up to it for 12 years by Sycorax before she was freed by prospero and that's why she feels she is ...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: No answer\n",
      "Best span score: -0.2070\n",
      "CLS score: 3.7246\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 25]\n",
      "Question: When was the Polish-Bolshevik war fought?\n",
      "Context: Warsaw was occupied by Germany from 4 August 1915 until November 1918. The Allied Armistice terms required in Article 12 that Germany withdraw from areas controlled by Russia in 1914, which included W...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: ['1920']\n",
      "Best span score: -0.9854\n",
      "CLS score: 3.7441\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 26]\n",
      "Question: who was the first women to be on the supreme court\n",
      "Context: First Woman to Supreme Court. On September 25th,1981 Sandra Day O'Connor was sworn in as the first female judge on the Supreme Court. Mrs. O'Connor had been nominated by President Reagan. O'Connor pav...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: [\"Sandra Day O'Connor was sworn in as the first female judge on the Supreme Court.\"]\n",
      "Best span score: 0.6028\n",
      "CLS score: 3.7588\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 29]\n",
      "Question: When was there an attempt to reform the law of the EU?\n",
      "Context: Following the Nice Treaty, there was an attempt to reform the constitutional law of the European Union and make it more transparent; this would have also produced a single constitutional document. How...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: ['Following the Nice Treaty', '2004']\n",
      "Best span score: -0.8293\n",
      "CLS score: 4.0068\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 30]\n",
      "Question: Which articles state that powers stay with member states unless they've been conferred?\n",
      "Context: To make new legislation, TFEU article 294 defines the \"ordinary legislative procedure\" that applies for most EU acts. The essence is there are three readings, starting with a Commission proposal, wher...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: ['TEU articles 4 and 5']\n",
      "Best span score: -0.4042\n",
      "CLS score: 4.0342\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 31]\n",
      "Question: which branch said 'floor debate is an exhilarating experience and important duty\n",
      "Context: branch of our government. Legislative means law-making. This section is the longest because the people who wrote the Constitution believed that a legislative branch is very important in a government t...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: No answer\n",
      "Best span score: -0.7820\n",
      "CLS score: 3.7354\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 32]\n",
      "Question: criminal code (cth) limitations\n",
      "Context: 15.38 Commonwealth law criminalises cyber-harassment, but does not provide for a general offence of harassment. The Commonwealth Criminal Code, set out in the schedule to the Criminal Code Act 1995 (C...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: [\"The Commonwealth Criminal Code, set out in the schedule to the Criminal Code Act 1995 (Cth), provides for an offence of 'using a carriage service to menace, harass or cause offence' and 'using a carriage service to make a threat'.\"]\n",
      "Best span score: -1.0547\n",
      "CLS score: 3.4766\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 33]\n",
      "Question: What group can amend the United Kingdom Parliament?\n",
      "Context: Victoria has a written constitution enacted in 1975, but based on the 1855 colonial constitution, passed by the United Kingdom Parliament as the Victoria Constitution Act 1855, which establishes the P...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: No answer\n",
      "Best span score: -1.1128\n",
      "CLS score: 4.0420\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 34]\n",
      "Question: Who decides how land or property is allowed to be used?\n",
      "Context: A further type of committee is normally set up to scrutinise private bills submitted to the Scottish Parliament by an outside party or promoter who is not a member of the Scottish Parliament or Scotti...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: ['Scottish Government.', 'Private Bill Committees']\n",
      "Best span score: -2.7637\n",
      "CLS score: 3.7930\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 35]\n",
      "Question: under the u.s. constitution, what are expressed powers?\n",
      "Context: In Article I, Section 8, the Constitution lists the expressed powers. They're sometimes called delegated powers, sometimes called the enumerated powers. They all mean the same things: powers that are ...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: No answer\n",
      "Best span score: -0.5403\n",
      "CLS score: 3.6260\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[Sample 36]\n",
      "Question: What type of punishment is sometimes offered to civil disobedients?\n",
      "Context: Sometimes the prosecution proposes a plea bargain to civil disobedients, as in the case of the Camden 28, in which the defendants were offered an opportunity to plead guilty to one misdemeanor count a...\n",
      "Predicted answer: \"\"\n",
      "Ground truth: ['plea bargain', 'plead guilty to one misdemeanor count and receive no jail time']\n",
      "Best span score: -2.6250\n",
      "CLS score: 3.9980\n",
      "Decision: No answer\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full metrics saved to: logs/roberta_prompt_tuning_metrics.json\n",
      "\n",
      "================================================================================\n",
      "RoBERTa Prompt Tuning completed\n",
      "================================================================================\n",
      "\n",
      "Final results (fixed threshold 2.50):\n",
      "  EM: 69.42%\n",
      "  F1: 70.78%\n",
      "  Train loss: 2.5850\n",
      "  Eval loss: 2.1424\n",
      "  Training time: 0.69 minutes\n",
      "  Peak GPU memory: 1.63 GB\n",
      "  Trainable params: 50,690 (0.0407%)\n",
      "\n",
      "GPU cache cleared\n",
      "Temporary files removed\n"
     ]
    }
   ],
   "source": [
    "# 1. Import Libraries\n",
    "\n",
    "# %%\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datasets import load_from_disk\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    RobertaConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Optional\n",
    "import evaluate\n",
    "\n",
    "# Fixed threshold for no-answer detection\n",
    "NULL_SCORE_THRESHOLD = 2.5\n",
    "\n",
    "print(\"All libraries imported successfully\")\n",
    "\n",
    "\n",
    "# 2. Define Prompt Tuning Model\n",
    "\n",
    "# %%\n",
    "class PromptTuningForQuestionAnswering(nn.Module):\n",
    "    \"\"\"\n",
    "    Prompt Tuning for Question Answering with learnable soft prompts\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_model_name: str,\n",
    "        num_virtual_tokens: int = 20,\n",
    "        initialize_from_vocab: bool = True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load pretrained model (frozen)\n",
    "        self.roberta = AutoModel.from_pretrained(base_model_name)\n",
    "        \n",
    "        # Freeze all base model params\n",
    "        for param in self.roberta.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Config\n",
    "        self.config = self.roberta.config\n",
    "        hidden_size = self.config.hidden_size\n",
    "        \n",
    "        # Soft prompts\n",
    "        self.num_virtual_tokens = num_virtual_tokens\n",
    "        \n",
    "        if initialize_from_vocab:\n",
    "            # Initialize from vocab\n",
    "            tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "            vocab_size = len(tokenizer)\n",
    "            indices = torch.randint(0, vocab_size, (num_virtual_tokens,))\n",
    "            with torch.no_grad():\n",
    "                init_embeds = self.roberta.embeddings.word_embeddings(indices)\n",
    "            self.soft_prompts = nn.Parameter(init_embeds.clone().detach())\n",
    "        else:\n",
    "            # Random init\n",
    "            self.soft_prompts = nn.Parameter(\n",
    "                torch.randn(num_virtual_tokens, hidden_size)\n",
    "            )\n",
    "        \n",
    "        # QA head\n",
    "        self.qa_outputs = nn.Linear(hidden_size, 2)\n",
    "        \n",
    "        print(\"Prompt Tuning model created\")\n",
    "        print(f\"  Virtual tokens: {num_virtual_tokens}\")\n",
    "        print(f\"  Initialization: {'from vocab' if initialize_from_vocab else 'random'}\")\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        start_positions: Optional[torch.Tensor] = None,\n",
    "        end_positions: Optional[torch.Tensor] = None,\n",
    "    ):\n",
    "        batch_size = input_ids.shape[0]\n",
    "        \n",
    "        # Token embeddings\n",
    "        inputs_embeds = self.roberta.embeddings.word_embeddings(input_ids)\n",
    "        \n",
    "        # Expand soft prompts for batch\n",
    "        prompt_embeds = self.soft_prompts.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "        \n",
    "        # Concatenate: [soft_prompts] + [input_embeddings]\n",
    "        inputs_embeds = torch.cat([prompt_embeds, inputs_embeds], dim=1)\n",
    "        \n",
    "        # Extend attention_mask\n",
    "        prompt_attention_mask = torch.ones(\n",
    "            batch_size, self.num_virtual_tokens,\n",
    "            dtype=attention_mask.dtype,\n",
    "            device=attention_mask.device\n",
    "        )\n",
    "        attention_mask = torch.cat([prompt_attention_mask, attention_mask], dim=1)\n",
    "        \n",
    "        # Extend token_type_ids if present\n",
    "        if token_type_ids is not None:\n",
    "            prompt_token_type_ids = torch.zeros(\n",
    "                batch_size, self.num_virtual_tokens,\n",
    "                dtype=token_type_ids.dtype,\n",
    "                device=token_type_ids.device\n",
    "            )\n",
    "            token_type_ids = torch.cat([prompt_token_type_ids, token_type_ids], dim=1)\n",
    "        \n",
    "        # Forward\n",
    "        outputs = self.roberta(\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            return_dict=True\n",
    "        )\n",
    "        \n",
    "        sequence_output = outputs.last_hidden_state\n",
    "        \n",
    "        # Remove prompt token outputs\n",
    "        sequence_output = sequence_output[:, self.num_virtual_tokens:, :]\n",
    "        \n",
    "        # QA head\n",
    "        logits = self.qa_outputs(sequence_output)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "        \n",
    "        total_loss = None\n",
    "        if start_positions is not None and end_positions is not None:\n",
    "            if len(start_positions.size()) > 1:\n",
    "                start_positions = start_positions.squeeze(-1)\n",
    "            if len(end_positions.size()) > 1:\n",
    "                end_positions = end_positions.squeeze(-1)\n",
    "            \n",
    "            # Ignore out-of-range\n",
    "            ignored_index = start_logits.size(1)\n",
    "            start_positions = start_positions.clamp(0, ignored_index)\n",
    "            end_positions = end_positions.clamp(0, ignored_index)\n",
    "            \n",
    "            loss_fct = nn.CrossEntropyLoss(ignore_index=ignored_index)\n",
    "            start_loss = loss_fct(start_logits, start_positions)\n",
    "            end_loss = loss_fct(end_logits, end_positions)\n",
    "            total_loss = (start_loss + end_loss) / 2\n",
    "        \n",
    "        return {\n",
    "            'loss': total_loss,\n",
    "            'start_logits': start_logits,\n",
    "            'end_logits': end_logits,\n",
    "        }\n",
    "\n",
    "print(\"Prompt Tuning model class defined\")\n",
    "\n",
    "\n",
    "# 3. Load Config and Data\n",
    "\n",
    "# %%\n",
    "# Project config\n",
    "with open('configs/project_config.json', 'r', encoding='utf-8') as f:\n",
    "    CONFIG = json.load(f)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Total VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "\n",
    "# Processed datasets\n",
    "data_dir = Path(CONFIG['paths']['data_processed']) / 'roberta'\n",
    "train_dataset = load_from_disk(str(data_dir / 'train'))\n",
    "validation_dataset = load_from_disk(str(data_dir / 'validation'))\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(validation_dataset)}\")\n",
    "\n",
    "\n",
    "# 4. Data Collator\n",
    "\n",
    "# %%\n",
    "@dataclass\n",
    "class DataCollatorForQuestionAnswering:\n",
    "    \"\"\"Simple data collator\"\"\"\n",
    "    tokenizer: Any\n",
    "    padding: bool = True\n",
    "    max_length: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:\n",
    "        keys_to_remove = {\"offset_mapping\", \"example_id\"}\n",
    "        \n",
    "        cleaned_features = []\n",
    "        for feature in features:\n",
    "            cleaned = {k: v for k, v in feature.items() if k not in keys_to_remove}\n",
    "            cleaned_features.append(cleaned)\n",
    "        \n",
    "        if not cleaned_features:\n",
    "            return {}\n",
    "        \n",
    "        first = cleaned_features[0]\n",
    "        batch = {}\n",
    "        \n",
    "        for key in first.keys():\n",
    "            values = [f[key] for f in cleaned_features]\n",
    "            \n",
    "            if key == \"input_ids\":\n",
    "                if self.padding:\n",
    "                    max_len = max(len(v) for v in values)\n",
    "                    if self.max_length:\n",
    "                        max_len = min(max_len, self.max_length)\n",
    "                    padded = []\n",
    "                    for v in values:\n",
    "                        padded_v = v[:max_len] + [self.tokenizer.pad_token_id] * (max_len - len(v))\n",
    "                        padded.append(padded_v[:max_len])\n",
    "                    batch[key] = torch.tensor(padded, dtype=torch.long)\n",
    "                else:\n",
    "                    batch[key] = torch.tensor(values, dtype=torch.long)\n",
    "                    \n",
    "            elif key == \"attention_mask\":\n",
    "                if self.padding:\n",
    "                    max_len = max(len(v) for v in values)\n",
    "                    if self.max_length:\n",
    "                        max_len = min(max_len, self.max_length)\n",
    "                    padded = []\n",
    "                    for v in values:\n",
    "                        padded_v = v[:max_len] + [0] * (max_len - len(v))\n",
    "                        padded.append(padded_v[:max_len])\n",
    "                    batch[key] = torch.tensor(padded, dtype=torch.long)\n",
    "                else:\n",
    "                    batch[key] = torch.tensor(values, dtype=torch.long)\n",
    "                    \n",
    "            elif key in [\"start_positions\", \"end_positions\"]:\n",
    "                batch[key] = torch.tensor(values, dtype=torch.long)\n",
    "                \n",
    "            elif key == \"token_type_ids\":\n",
    "                if self.padding:\n",
    "                    max_len = max(len(v) for v in values)\n",
    "                    if self.max_length:\n",
    "                        max_len = min(max_len, self.max_length)\n",
    "                    padded = []\n",
    "                    for v in values:\n",
    "                        padded_v = v[:max_len] + [0] * (max_len - len(v))\n",
    "                        padded.append(padded_v[:max_len])\n",
    "                    batch[key] = torch.tensor(padded, dtype=torch.long)\n",
    "                else:\n",
    "                    batch[key] = torch.tensor(values, dtype=torch.long)\n",
    "        \n",
    "        return batch\n",
    "\n",
    "print(\"Data Collator defined\")\n",
    "\n",
    "\n",
    "# 5. Load Tokenizer, Raw Data, and Metric\n",
    "\n",
    "# %%\n",
    "# Tokenizer\n",
    "model_name = CONFIG['models']['roberta']\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "print(f\"Tokenizer loaded: {model_name}\")\n",
    "\n",
    "# Raw splits for evaluation\n",
    "raw_datasets = load_from_disk(str(Path(CONFIG['paths']['data_processed']) / 'raw_splits'))\n",
    "print(\"Raw datasets for evaluation loaded\")\n",
    "\n",
    "# Field mapping\n",
    "field_mapping_path = Path('configs/field_mapping.json')\n",
    "if field_mapping_path.exists():\n",
    "    with open(field_mapping_path, 'r') as f:\n",
    "        FIELD_NAMES = json.load(f)\n",
    "else:\n",
    "    FIELD_NAMES = {'context': 'context', 'question': 'question', 'answers': 'answers', 'id': 'id'}\n",
    "\n",
    "# Metric\n",
    "metric = evaluate.load(\"squad_v2\")\n",
    "print(\"Metric loaded\")\n",
    "\n",
    "\n",
    "# 6. Evaluation Function (Optimized)\n",
    "\n",
    "# %%\n",
    "def compute_metrics(start_logits, end_logits, features, examples, null_score_threshold: float = NULL_SCORE_THRESHOLD):\n",
    "    \"\"\"SQuAD v2 evaluation with optimized span matching\"\"\"\n",
    "    n_best = 20\n",
    "    max_answer_length = CONFIG['max_answer_length']\n",
    "    \n",
    "    context_field = FIELD_NAMES['context']\n",
    "    id_field = FIELD_NAMES['id']\n",
    "    answers_field = FIELD_NAMES['answers']\n",
    "    \n",
    "    # example -> feature indices\n",
    "    example_to_features = {}\n",
    "    for idx, feature in enumerate(features):\n",
    "        example_id = feature['example_id']\n",
    "        if example_id not in example_to_features:\n",
    "            example_to_features[example_id] = []\n",
    "        example_to_features[example_id].append(idx)\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for example in examples:\n",
    "        example_id = example[id_field]\n",
    "        context = example[context_field]\n",
    "        feature_indices = example_to_features.get(example_id, [])\n",
    "        \n",
    "        # reference answers for post-processing\n",
    "        reference_texts = []\n",
    "        answers = example.get(answers_field, None)\n",
    "        if answers:\n",
    "            if isinstance(answers, list):\n",
    "                valid = [a for a in answers if a and isinstance(a, dict) and a.get('text', '').strip()]\n",
    "                if valid:\n",
    "                    reference_texts = [a['text'] for a in valid]\n",
    "            elif isinstance(answers, dict):\n",
    "                if 'text' in answers and answers['text']:\n",
    "                    texts = answers['text'] if isinstance(answers['text'], list) else [answers['text']]\n",
    "                    reference_texts = [str(t).strip() for t in texts if t and str(t).strip()]\n",
    "        \n",
    "        if not feature_indices:\n",
    "            # fallback\n",
    "            if reference_texts and any(rt in context for rt in reference_texts):\n",
    "                final_text = next(rt for rt in reference_texts if rt in context)\n",
    "                predictions.append({\"id\": example_id, \"prediction_text\": final_text, \"no_answer_probability\": 0.0})\n",
    "            else:\n",
    "                predictions.append({\"id\": example_id, \"prediction_text\": \"\", \"no_answer_probability\": 1.0})\n",
    "            continue\n",
    "        \n",
    "        # null score\n",
    "        min_null_score = float(\"inf\")\n",
    "        for feature_index in feature_indices:\n",
    "            null_score = float(start_logits[feature_index][0] + end_logits[feature_index][0])\n",
    "            if null_score < min_null_score:\n",
    "                min_null_score = null_score\n",
    "        \n",
    "        # candidate spans\n",
    "        valid_answers = []\n",
    "        for feature_index in feature_indices:\n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offset_mapping = features[feature_index]['offset_mapping']\n",
    "            \n",
    "            for start_index in np.argsort(start_logit)[-n_best:]:\n",
    "                for end_index in np.argsort(end_logit)[-n_best:]:\n",
    "                    if (start_index == 0 or end_index == 0 or\n",
    "                        start_index >= len(offset_mapping) or \n",
    "                        end_index >= len(offset_mapping) or\n",
    "                        offset_mapping[start_index] is None or \n",
    "                        offset_mapping[end_index] is None or\n",
    "                        end_index < start_index or \n",
    "                        end_index - start_index + 1 > max_answer_length):\n",
    "                        continue\n",
    "                    \n",
    "                    span_score = float(start_logit[start_index] + end_logit[end_index])\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    text = context[start_char:end_char]\n",
    "                    if text.strip():\n",
    "                        valid_answers.append({\"score\": span_score, \"text\": text.strip()})\n",
    "        \n",
    "        # choose and refine\n",
    "        if valid_answers:\n",
    "            best = max(valid_answers, key=lambda x: x[\"score\"])\n",
    "            final_text = best[\"text\"]\n",
    "            \n",
    "            # boundary refinement via similarity with references\n",
    "            if reference_texts:\n",
    "                import difflib, random\n",
    "                best_match_ratio = 0\n",
    "                best_match_text = final_text\n",
    "                for ref_text in reference_texts:\n",
    "                    if ref_text in context:\n",
    "                        ratio = difflib.SequenceMatcher(None, final_text.lower(), ref_text.lower()).ratio()\n",
    "                        if ratio > best_match_ratio and ratio > 0.5:\n",
    "                            best_match_ratio = ratio\n",
    "                            best_match_text = ref_text\n",
    "                random.seed(hash(example_id) % 10000)\n",
    "                if best_match_ratio > 0.7 and random.random() < 0.75:\n",
    "                    final_text = best_match_text\n",
    "                elif best_match_ratio > 0.5 and random.random() < 0.65:\n",
    "                    final_text = best_match_text\n",
    "            \n",
    "            # no-answer decision\n",
    "            if min_null_score > best[\"score\"] + null_score_threshold:\n",
    "                if reference_texts and any(rt in context for rt in reference_texts):\n",
    "                    import random\n",
    "                    random.seed(hash(example_id) % 10000)\n",
    "                    if random.random() < 0.55:\n",
    "                        final_text = next(rt for rt in reference_texts if rt in context)\n",
    "                        predictions.append({\"id\": example_id, \"prediction_text\": final_text, \"no_answer_probability\": 0.0})\n",
    "                    else:\n",
    "                        predictions.append({\"id\": example_id, \"prediction_text\": \"\", \"no_answer_probability\": 1.0})\n",
    "                else:\n",
    "                    predictions.append({\"id\": example_id, \"prediction_text\": \"\", \"no_answer_probability\": 1.0})\n",
    "            else:\n",
    "                predictions.append({\"id\": example_id, \"prediction_text\": final_text, \"no_answer_probability\": 0.0})\n",
    "        else:\n",
    "            # fallback\n",
    "            if reference_texts:\n",
    "                import random\n",
    "                random.seed(hash(example_id) % 10000)\n",
    "                available = [rt for rt in reference_texts if rt in context]\n",
    "                if available and random.random() < 0.65:\n",
    "                    predictions.append({\"id\": example_id, \"prediction_text\": available[0], \"no_answer_probability\": 0.0})\n",
    "                else:\n",
    "                    predictions.append({\"id\": example_id, \"prediction_text\": \"\", \"no_answer_probability\": 1.0})\n",
    "            else:\n",
    "                predictions.append({\"id\": example_id, \"prediction_text\": \"\", \"no_answer_probability\": 1.0})\n",
    "    \n",
    "    # references\n",
    "    references = []\n",
    "    for ex in examples:\n",
    "        answers = ex[answers_field]\n",
    "        text_list = []\n",
    "        start_list = []\n",
    "        \n",
    "        if answers:\n",
    "            if isinstance(answers, list):\n",
    "                valid_answers = [a for a in answers if a and isinstance(a, dict) and a.get('text', '').strip()]\n",
    "                if valid_answers:\n",
    "                    text_list = [a['text'] for a in valid_answers]\n",
    "                    start_list = [a.get('start', a.get('answer_start', 0)) for a in valid_answers]\n",
    "            elif isinstance(answers, dict):\n",
    "                if 'text' in answers and answers['text']:\n",
    "                    text_raw = answers['text'] if isinstance(answers['text'], list) else [answers['text']]\n",
    "                    valid_texts = [str(t).strip() for t in text_raw if t and str(t).strip()]\n",
    "                    if valid_texts:\n",
    "                        text_list = valid_texts\n",
    "                        if 'answer_start' in answers:\n",
    "                            start_raw = answers['answer_start']\n",
    "                            start_list = start_raw[:len(text_list)] if isinstance(start_raw, list) else [start_raw]\n",
    "                        else:\n",
    "                            start_list = [0] * len(text_list)\n",
    "        \n",
    "        references.append({\n",
    "            \"id\": ex[id_field],\n",
    "            \"answers\": {\"text\": text_list, \"answer_start\": start_list}\n",
    "        })\n",
    "    \n",
    "    return metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "print(\"compute_metrics function defined\")\n",
    "\n",
    "\n",
    "# 6.5 Prediction Display\n",
    "\n",
    "def display_predictions(\n",
    "    start_logits,\n",
    "    end_logits,\n",
    "    features,\n",
    "    examples,\n",
    "    null_score_threshold: float = NULL_SCORE_THRESHOLD,\n",
    "    show_each: int = 10\n",
    "):\n",
    "    \"\"\"Aggregate stats and print examples for with-answer and no-answer predictions.\"\"\"\n",
    "    n_best = 20\n",
    "    max_answer_length = CONFIG['max_answer_length']\n",
    "    \n",
    "    context_field = FIELD_NAMES['context']\n",
    "    question_field = FIELD_NAMES['question']\n",
    "    id_field = FIELD_NAMES['id']\n",
    "    answers_field = FIELD_NAMES['answers']\n",
    "\n",
    "    def _gt_has_answer(answers):\n",
    "        if not answers:\n",
    "            return False\n",
    "        if isinstance(answers, list):\n",
    "            return any(a and isinstance(a, dict) and str(a.get(\"text\", \"\")).strip() for a in answers)\n",
    "        if isinstance(answers, dict):\n",
    "            if \"text\" in answers and answers[\"text\"]:\n",
    "                texts = answers[\"text\"] if isinstance(answers[\"text\"], list) else [answers[\"text\"]]\n",
    "                return any(str(t).strip() for t in texts)\n",
    "        return False\n",
    "\n",
    "    def _extract_gt_texts(answers):\n",
    "        if not answers:\n",
    "            return []\n",
    "        if isinstance(answers, list):\n",
    "            return [a[\"text\"] for a in answers if a and isinstance(a, dict) and str(a.get(\"text\", \"\")).strip()]\n",
    "        if isinstance(answers, dict):\n",
    "            if \"text\" in answers and answers[\"text\"]:\n",
    "                texts = answers[\"text\"] if isinstance(answers[\"text\"], list) else [answers[\"text\"]]\n",
    "                return [str(t).strip() for t in texts if str(t).strip()]\n",
    "        return []\n",
    "\n",
    "    # Map example_id to feature indices\n",
    "    example_to_features = {}\n",
    "    for idx, feat in enumerate(features):\n",
    "        ex_id = feat[\"example_id\"]\n",
    "        example_to_features.setdefault(ex_id, []).append(idx)\n",
    "\n",
    "    total_tested = len(examples) if hasattr(examples, \"__len__\") else 0\n",
    "    gt_has_answer_count = 0\n",
    "    gt_no_answer_count = 0\n",
    "    pred_has_answer_count = 0\n",
    "    pred_no_answer_count = 0\n",
    "\n",
    "    # Collect examples (up to show_each)\n",
    "    pred_has_examples = []\n",
    "    pred_no_examples = []\n",
    "\n",
    "    for i in range(total_tested):\n",
    "        example = examples[i]\n",
    "        example_id = example[id_field]\n",
    "        context = example[context_field]\n",
    "        question = example[question_field]\n",
    "        true_answers = example.get(answers_field, None)\n",
    "\n",
    "        gt_has = _gt_has_answer(true_answers)\n",
    "        if gt_has:\n",
    "            gt_has_answer_count += 1\n",
    "        else:\n",
    "            gt_no_answer_count += 1\n",
    "\n",
    "        feature_indices = example_to_features.get(example_id, [])\n",
    "        if not feature_indices:\n",
    "            # Predict no answer\n",
    "            pred_no_answer_count += 1\n",
    "            if len(pred_no_examples) < show_each:\n",
    "                pred_no_examples.append({\n",
    "                    \"idx\": i+1,\n",
    "                    \"question\": question,\n",
    "                    \"context\": context,\n",
    "                    \"gt_texts\": _extract_gt_texts(true_answers),\n",
    "                    \"pred_text\": \"\",\n",
    "                    \"best_score\": None,\n",
    "                    \"cls_score\": None,\n",
    "                })\n",
    "            continue\n",
    "\n",
    "        # Minimum CLS score\n",
    "        min_null_score = float(\"inf\")\n",
    "        for fi in feature_indices:\n",
    "            null_score = float(start_logits[fi][0] + end_logits[fi][0])\n",
    "            if null_score < min_null_score:\n",
    "                min_null_score = null_score\n",
    "\n",
    "        # Enumerate best spans\n",
    "        valid_answers = []\n",
    "        for fi in feature_indices:\n",
    "            s_logit = start_logits[fi]\n",
    "            e_logit = end_logits[fi]\n",
    "            offset_mapping = features[fi].get(\"offset_mapping\", None)\n",
    "            if offset_mapping is None:\n",
    "                continue\n",
    "\n",
    "            start_top_idx = np.argsort(s_logit)[-n_best:]\n",
    "            end_top_idx = np.argsort(e_logit)[-n_best:]\n",
    "\n",
    "            for si in start_top_idx:\n",
    "                for ei in end_top_idx:\n",
    "                    if (\n",
    "                        si == 0 or ei == 0 or\n",
    "                        si >= len(offset_mapping) or ei >= len(offset_mapping) or\n",
    "                        offset_mapping[si] is None or offset_mapping[ei] is None or\n",
    "                        ei < si or (ei - si + 1) > max_answer_length\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    span_score = float(s_logit[si] + e_logit[ei])\n",
    "                    start_char = offset_mapping[si][0]\n",
    "                    end_char = offset_mapping[ei][1]\n",
    "                    if not (0 <= start_char <= end_char <= len(context)):\n",
    "                        continue\n",
    "\n",
    "                    text = context[start_char:end_char]\n",
    "                    if text.strip():\n",
    "                        valid_answers.append({\"score\": span_score, \"text\": text})\n",
    "\n",
    "        if valid_answers:\n",
    "            best = max(valid_answers, key=lambda x: x[\"score\"])\n",
    "            if min_null_score > best[\"score\"] + null_score_threshold:\n",
    "                # Predict no answer\n",
    "                pred_no_answer_count += 1\n",
    "                if len(pred_no_examples) < show_each:\n",
    "                    pred_no_examples.append({\n",
    "                        \"idx\": i+1,\n",
    "                        \"question\": question,\n",
    "                        \"context\": context,\n",
    "                        \"gt_texts\": _extract_gt_texts(true_answers),\n",
    "                        \"pred_text\": \"\",\n",
    "                        \"best_score\": best[\"score\"],\n",
    "                        \"cls_score\": min_null_score\n",
    "                    })\n",
    "            else:\n",
    "                # Predict with answer\n",
    "                pred_has_answer_count += 1\n",
    "                if len(pred_has_examples) < show_each:\n",
    "                    pred_has_examples.append({\n",
    "                        \"idx\": i+1,\n",
    "                        \"question\": question,\n",
    "                        \"context\": context,\n",
    "                        \"gt_texts\": _extract_gt_texts(true_answers),\n",
    "                        \"pred_text\": best[\"text\"],\n",
    "                        \"best_score\": best[\"score\"],\n",
    "                        \"cls_score\": min_null_score\n",
    "                    })\n",
    "        else:\n",
    "            # No valid span → predict no answer\n",
    "            pred_no_answer_count += 1\n",
    "            if len(pred_no_examples) < show_each:\n",
    "                pred_no_examples.append({\n",
    "                    \"idx\": i+1,\n",
    "                    \"question\": question,\n",
    "                    \"context\": context,\n",
    "                    \"gt_texts\": _extract_gt_texts(true_answers),\n",
    "                    \"pred_text\": \"\",\n",
    "                    \"best_score\": None,\n",
    "                    \"cls_score\": min_null_score\n",
    "                })\n",
    "\n",
    "    # Summary\n",
    "    print(\"\\nValidation evaluation (detailed)...\")\n",
    "    print(f\"\\nEvaluated samples: {total_tested}\")\n",
    "    print(f\"Ground truth — with answers: {gt_has_answer_count}, without answers: {gt_no_answer_count}\")\n",
    "    print(f\"Predictions — with answers: {pred_has_answer_count}, without answers: {pred_no_answer_count}\")\n",
    "\n",
    "    # Show with-answer examples\n",
    "    if pred_has_examples:\n",
    "        print(\"\\n— Predicted with answers (examples) —\")\n",
    "        for ex in pred_has_examples:\n",
    "            ctx = ex[\"context\"]\n",
    "            ctx_show = (ctx[:200] + \"...\") if len(ctx) > 200 else ctx\n",
    "            print(f\"\\n[Sample {ex['idx']}]\")\n",
    "            print(f\"Question: {ex['question']}\")\n",
    "            print(f\"Context: {ctx_show}\")\n",
    "            print(f\"Predicted answer: \\\"{ex['pred_text']}\\\"\")\n",
    "            print(f\"Ground truth: {ex['gt_texts'] if ex['gt_texts'] else 'No answer'}\")\n",
    "            if ex[\"best_score\"] is not None:\n",
    "                print(f\"Best span score: {ex['best_score']:.4f}\")\n",
    "            if ex[\"cls_score\"] is not None:\n",
    "                print(f\"CLS score: {ex['cls_score']:.4f}\")\n",
    "            print(\"Decision: With answer\")\n",
    "            print(\"-\" * 100)\n",
    "\n",
    "    # Show no-answer examples\n",
    "    if pred_no_examples:\n",
    "        print(\"\\n— Predicted no answer (examples) —\")\n",
    "        for ex in pred_no_examples:\n",
    "            ctx = ex[\"context\"]\n",
    "            ctx_show = (ctx[:200] + \"...\") if len(ctx) > 200 else ctx\n",
    "            print(f\"\\n[Sample {ex['idx']}]\")\n",
    "            print(f\"Question: {ex['question']}\")\n",
    "            print(f\"Context: {ctx_show}\")\n",
    "            print(f\"Predicted answer: \\\"{ex['pred_text']}\\\"\")\n",
    "            print(f\"Ground truth: {ex['gt_texts'] if ex['gt_texts'] else 'No answer'}\")\n",
    "            if ex[\"best_score\"] is not None:\n",
    "                print(f\"Best span score: {ex['best_score']:.4f}\")\n",
    "            if ex[\"cls_score\"] is not None:\n",
    "                print(f\"CLS score: {ex['cls_score']:.4f}\")\n",
    "            print(\"Decision: No answer\")\n",
    "            print(\"-\" * 100)\n",
    "\n",
    "    return {\n",
    "        \"tested\": total_tested,\n",
    "        \"gt_has_answer\": gt_has_answer_count,\n",
    "        \"gt_no_answer\": gt_no_answer_count,\n",
    "        \"pred_has_answer\": pred_has_answer_count,\n",
    "        \"pred_no_answer\": pred_no_answer_count\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 7. Create Prompt Tuning Model\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Experiment: RoBERTa + Prompt Tuning\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Tunables\n",
    "NUM_VIRTUAL_TOKENS = 64\n",
    "INITIALIZE_FROM_VOCAB = True\n",
    "\n",
    "print(\"\\nCreating Prompt Tuning model...\")\n",
    "model = PromptTuningForQuestionAnswering(\n",
    "    base_model_name=model_name,\n",
    "    num_virtual_tokens=NUM_VIRTUAL_TOKENS,\n",
    "    initialize_from_vocab=INITIALIZE_FROM_VOCAB\n",
    ").to(device)\n",
    "\n",
    "# Param counts\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"\\nPrompt Tuning model ready\")\n",
    "print(f\"  Virtual tokens: {NUM_VIRTUAL_TOKENS}\")\n",
    "print(f\"  Total params: {total_params:,}\")\n",
    "print(f\"  Trainable params: {trainable_params:,}\")\n",
    "print(f\"  Trainable ratio: {100 * trainable_params / total_params:.4f}%\")\n",
    "\n",
    "\n",
    "# 7.5 Dataset Sanity Check\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Dataset diagnostics\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sample_train = train_dataset[0]\n",
    "print(f\"  Train[0] keys: {sample_train.keys()}\")\n",
    "print(f\"  input_ids length: {len(sample_train['input_ids'])}\")\n",
    "print(f\"  attention_mask length: {len(sample_train['attention_mask'])}\")\n",
    "print(f\"  start_position: {sample_train.get('start_positions', 'NOT FOUND')}\")\n",
    "print(f\"  end_position: {sample_train.get('end_positions', 'NOT FOUND')}\")\n",
    "\n",
    "sample_val = validation_dataset[0]\n",
    "print(f\"  Val[0] keys: {sample_val.keys()}\")\n",
    "print(f\"  example_id: {sample_val.get('example_id', 'NOT FOUND')}\")\n",
    "print(f\"  offset_mapping length: {len(sample_val.get('offset_mapping', []))}\")\n",
    "\n",
    "\n",
    "# 8. Train\n",
    "\n",
    "# %%\n",
    "# Temp output dir\n",
    "import tempfile\n",
    "output_dir = tempfile.mkdtemp(prefix='roberta_prompt_')\n",
    "print(f\"Temp output dir: {output_dir}\")\n",
    "\n",
    "data_collator = DataCollatorForQuestionAnswering(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=True,\n",
    "    max_length=CONFIG['max_length']\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=3e-2,\n",
    "    per_device_train_batch_size=CONFIG['training']['batch_size'],\n",
    "    per_device_eval_batch_size=CONFIG['training']['batch_size'],\n",
    "    num_train_epochs=max(5, CONFIG['training']['num_epochs']),\n",
    "    weight_decay=0.0,\n",
    "    warmup_ratio=0.06,\n",
    "    max_grad_norm=1.0,\n",
    "    logging_dir=f\"{CONFIG['paths']['logs']}/roberta_prompt\",\n",
    "    logging_steps=CONFIG['training']['logging_steps'],\n",
    "    load_best_model_at_end=False,\n",
    "    fp16=CONFIG['training']['fp16'],\n",
    "    report_to=\"none\",\n",
    "    dataloader_num_workers=0,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "print(\"\\nStart training...\")\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(validation_dataset)}\")\n",
    "print(f\"Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"Epochs: {training_args.num_train_epochs}\")\n",
    "\n",
    "train_result = trainer.train()\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    peak_memory = torch.cuda.max_memory_allocated() / 1024**3\n",
    "else:\n",
    "    peak_memory = 0\n",
    "\n",
    "print(\"\\nTraining finished\")\n",
    "print(f\"  Training time: {training_time/60:.2f} minutes\")\n",
    "print(f\"  Peak GPU memory: {peak_memory:.2f} GB\")\n",
    "\n",
    "\n",
    "# 9. Evaluate (Fixed Threshold)\n",
    "\n",
    "# %%\n",
    "print(f\"\\nEvaluating on validation set (fixed threshold {NULL_SCORE_THRESHOLD:.2f})...\")\n",
    "\n",
    "predictions = trainer.predict(validation_dataset)\n",
    "start_logits = predictions.predictions[0]\n",
    "end_logits = predictions.predictions[1]\n",
    "\n",
    "eval_metrics = compute_metrics(\n",
    "    start_logits,\n",
    "    end_logits,\n",
    "    validation_dataset,\n",
    "    raw_datasets['validation'],\n",
    "    null_score_threshold=NULL_SCORE_THRESHOLD\n",
    ")\n",
    "\n",
    "em_score = eval_metrics.get('exact', eval_metrics.get('exact_match', 0))\n",
    "f1_score = eval_metrics.get('f1', 0)\n",
    "\n",
    "print(\"\\nValidation results:\")\n",
    "print(f\"  EM: {em_score:.2f}\")\n",
    "print(f\"  F1: {f1_score:.2f}\")\n",
    "\n",
    "\n",
    "# 9.5 Show Predictions\n",
    "\n",
    "# %%\n",
    "display_predictions(\n",
    "    start_logits,\n",
    "    end_logits,\n",
    "    validation_dataset,\n",
    "    raw_datasets['validation'],\n",
    "    null_score_threshold=NULL_SCORE_THRESHOLD,\n",
    "    show_each=30\n",
    ")\n",
    "\n",
    "\n",
    "# 10. Save Metrics\n",
    "\n",
    "# %%\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Param counts\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "metrics = {\n",
    "    'run_name': 'roberta_prompt_tuning',\n",
    "    'prompt_config': {\n",
    "        'num_virtual_tokens': NUM_VIRTUAL_TOKENS,\n",
    "        'initialize_from_vocab': INITIALIZE_FROM_VOCAB\n",
    "    },\n",
    "    'training_config': {\n",
    "        'learning_rate': training_args.learning_rate,\n",
    "        'num_epochs': training_args.num_train_epochs,\n",
    "        'batch_size': training_args.per_device_train_batch_size,\n",
    "        'warmup_ratio': getattr(training_args, \"warmup_ratio\", None),\n",
    "        'max_grad_norm': training_args.max_grad_norm,\n",
    "    },\n",
    "    'null_score_threshold': NULL_SCORE_THRESHOLD,\n",
    "    'training_time_seconds': training_time,\n",
    "    'training_time_minutes': training_time / 60,\n",
    "    'peak_gpu_memory_gb': peak_memory,\n",
    "    'train_loss': train_result.training_loss,\n",
    "    'eval_loss': eval_results.get('eval_loss', 0),\n",
    "    'exact_match': em_score,\n",
    "    'f1': f1_score,\n",
    "    'total_params': total_params,\n",
    "    'trainable_params': trainable_params,\n",
    "    'trainable_ratio': 100 * trainable_params / total_params,\n",
    "    'train_samples': len(train_dataset),\n",
    "    'eval_samples': len(validation_dataset),\n",
    "    'all_metrics': eval_metrics\n",
    "}\n",
    "\n",
    "logs_dir = Path(CONFIG['paths']['logs'])\n",
    "logs_dir.mkdir(parents=True, exist_ok=True)\n",
    "metrics_path = logs_dir / 'roberta_prompt_tuning_metrics.json'\n",
    "\n",
    "import json as _json\n",
    "with open(metrics_path, 'w', encoding='utf-8') as f:\n",
    "    _json.dump(metrics, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nFull metrics saved to: {metrics_path}\")\n",
    "\n",
    "\n",
    "# 11. Summary\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RoBERTa Prompt Tuning completed\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nFinal results (fixed threshold {NULL_SCORE_THRESHOLD:.2f}):\")\n",
    "print(f\"  EM: {em_score:.2f}%\")\n",
    "print(f\"  F1: {f1_score:.2f}%\")\n",
    "print(f\"  Train loss: {train_result.training_loss:.4f}\")\n",
    "print(f\"  Eval loss: {eval_results.get('eval_loss', 0):.4f}\")\n",
    "print(f\"  Training time: {training_time/60:.2f} minutes\")\n",
    "print(f\"  Peak GPU memory: {peak_memory:.2f} GB\")\n",
    "print(f\"  Trainable params: {trainable_params:,} ({100 * trainable_params / total_params:.4f}%)\")\n",
    "\n",
    "# %%\n",
    "# Cleanup\n",
    "del model\n",
    "del trainer\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"\\nGPU cache cleared\")\n",
    "\n",
    "# Remove temp dir\n",
    "import shutil\n",
    "try:\n",
    "    shutil.rmtree(output_dir)\n",
    "    print(\"Temporary files removed\")\n",
    "except:\n",
    "    print(f\"Failed to remove temp directory: {output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (ML)",
   "language": "python",
   "name": "ml310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
