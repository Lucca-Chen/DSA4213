{
  "project_name": "Legal QA Fine-tuning",
  "random_seed": 42,
  "device": "cuda",
  "dataset_name": "isaacus/LegalQAEval",
  "train_split_ratio": 0.9,
  "valid_split_ratio": 0.1,
  "models": {
    "roberta": "roberta-base",
    "distilbert": "distilbert-base-uncased"
  },
  "max_length": 384,
  "doc_stride": 128,
  "max_answer_length": 30,
  "training": {
    "learning_rate": 3e-05,
    "batch_size": 8,
    "num_epochs": 3,
    "warmup_steps": 500,
    "weight_decay": 0.01,
    "evaluation_strategy": "epoch",
    "save_strategy": "epoch",
    "logging_steps": 100,
    "fp16": true
  },
  "lora": {
    "r": 8,
    "lora_alpha": 16,
    "target_modules": [
      "query",
      "value"
    ],
    "lora_dropout": 0.05,
    "bias": "none",
    "task_type": "QUESTION_ANS"
  },
  "paths": {
    "data": "data",
    "data_processed": "data/processed",
    "outputs": "outputs",
    "outputs_roberta_full": "outputs/roberta_full",
    "outputs_roberta_lora": "outputs/roberta_lora",
    "outputs_distilbert_full": "outputs/distilbert_full",
    "outputs_distilbert_lora": "outputs/distilbert_lora",
    "logs": "logs",
    "reports": "reports",
    "configs": "configs"
  }
}